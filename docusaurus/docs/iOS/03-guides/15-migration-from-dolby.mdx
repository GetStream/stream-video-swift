---
title: Migration Guide from Dolby.io to Stream SDK
---

## Summary
This migration guide is designed to assist developers in transitioning their Audioroom applications from the Dolby.io Conference SDK to the Stream SDK. Our aim is to provide a comprehensive, step-by-step walkthrough that not only highlights the differences between the two SDKs but also showcases the unique features and enhancements offered by Stream. Whether you are looking to leverage advanced functionalities, improve performance, or simply explore new avenues with Stream, this guide will equip you with all the necessary tools and knowledge for a seamless migration.

## Introduction
Welcome to the definitive guide for migrating your AudioRoom app from Dolby.io Conference SDK to Stream SDK. In the dynamic world of digital audio communication, staying at the forefront with the most efficient and feature-rich tools is key to delivering outstanding user experiences. This guide is meticulously crafted to support developers who have been utilizing Dolby.io for their audio conferencing solutions and are now poised to embrace the innovative features and advanced capabilities of the Stream SDK.

Dolby.io has established itself as a formidable solution in the realm of audio conferencing, celebrated for its superior sound quality and reliable streaming performance. However, as the requirements for digital audio communication continue to evolve, the need for more adaptable, scalable, and feature-intensive platforms becomes apparent. Stream SDK emerges as an ideal choice in this scenario, offering a modern, scalable, and comprehensive toolkit tailored for contemporary audio communication applications.

Stream SDK distinguishes itself through its state-of-the-art architecture, enhanced scalability, and a broad spectrum of features specifically designed for modern audio communication needs. It promises not just an improvement in audio quality but also introduces advanced functionalities like better data security, a more intuitive API, and innovative features that cater to the diverse demands of today's users.

Through this guide, you will:
- Discover the fundamental differences and similarities between Dolby.io and Stream SDKs, particularly in the context of AudioRoom applications.
- Receive detailed, step-by-step instructions to ensure a smooth and efficient migration process.
- Learn about the additional capabilities and benefits that Stream SDK brings to your audio conferencing solutions.
- Find solutions to common challenges and answers to frequently asked questions during the transition.

By the end of this guide, you will be equipped with a thorough understanding of how Stream SDK can enhance your audio conferencing applications, providing a clear rationale for its adoption as a superior alternative to Dolby.io in your technology stack. Let's dive into this journey toward achieving more advanced, efficient, and feature-rich audio conferencing experiences with Stream SDK.

## Prerequisites
Before diving into the migration process, it's essential to establish a clear starting point and outline the capabilities of the existing SwiftUI AudioRoom application using Dolby.io SDK. This guide assumes that you are already familiar with the basics of SwiftUI and have an existing AudioRoom application built with Dolby.io SDK. If you don't you can use our demo that can be found [here](add-link) The application currently includes the following features:

- **Join/Leave a Call**: Users can join or leave audio calls, facilitating easy participation in audio conferences.
- **View Participants**: The app displays a list or grid of participants currently in the call, making it easy to see who is involved in the conference.
- **Mute/Unmute Functionality**: Users have the ability to mute and unmute themselves, providing control over their participation in the conversation.
- **Speaking Indicator**: When a participant speaks, their avatar is highlighted, visually indicating who is actively contributing to the conversation.

As we migrate to Stream SDK, we will not only replicate these existing features but also introduce additional functionalities to enhance the user experience and leverage the advanced capabilities of the Stream SDK. The added features will include:

1. **Improved Audio Quality**: Leveraging Stream's superior audio processing to provide clearer and more reliable audio communication.
2. **Enhanced User Interface**: A more intuitive and user-friendly interface, taking advantage of SwiftUI's capabilities.
3. **Simpler code**: Implementing an Audioroom app with the Stream SDK should be easy and the code should be clear. 
4. **Request to speak**: We will implement a simple permission system, where a participants can request to talk and a host can approve or reject their request.

This guide assumes that you have the following setup and knowledge:

- A working SwiftUI AudioRoom application built with Dolby.io SDK.
- Basic knowledge of audio streaming concepts and audio room functionalities.
- Familiarity with Swift and SwiftUI for iOS app development.
- Understanding of Dolby.io SDK's core features and implementation within your existing app.
- Access to both Dolby.io and Stream SDKs, along with necessary developer accounts and permissions.

With these prerequisites in place, you'll be well-prepared to embark on the migration process, transforming your app with enhanced features and capabilities offered by the Stream SDK.

## Key Differences
Understanding the core differences between Dolby.io SDK and Stream SDK is essential for a smooth migration process. This section highlights the significant distinctions that impact how you will adapt your existing AudioRoom application when transitioning to Stream SDK.

1. **Swift Concurrency and SwiftUI Optimization**: 
   - **Dolby.io SDK**: This SDK does not natively support Swift concurrency, and its APIs are not fully optimized for SwiftUI. This can result in more complex integration with SwiftUI-based applications and may require additional workarounds to manage asynchronous operations.
   - **Stream SDK**: In contrast, Stream SDK is designed with native support for Swift concurrency, offering a more seamless integration with SwiftUI. This results in a more straightforward, efficient coding experience, particularly for developers working with modern Swift development practices.

2. **Terminology: Conference vs. Call**:
   - **Dolby.io SDK**: In Dolby.io, the primary feature of connecting users in an audio session is referred to as a 'Conference'. This terminology is consistent across their documentation and API.
   - **Stream SDK**: Stream SDK, on the other hand, uses the term 'Call' to describe similar functionality. This is more than just a semantic difference; it reflects in the API naming conventions and documentation. Being aware of this terminology change is crucial for understanding the Stream SDK's structure and documentation.

3. **Extensibility and Permission System**:
   - **Dolby.io SDK**: While Dolby.io SDK offers a range of features for audio conferencing, it may not provide as much flexibility when it comes to extending the SDK's capabilities, particularly regarding building a custom permission system.
   - **Stream SDK**: Stream SDK stands out with its extensibility, especially in implementing advanced features like a permission system. This flexibility allows for more granular control over user roles and permissions, which is particularly beneficial for creating more sophisticated or customized audio room experiences.

In summary, the Stream SDK offers a more modern and streamlined approach, especially for developers working with SwiftUI and Swift concurrency. Its terminology and extensible nature also make it a more versatile choice for building advanced audio conferencing applications. These key differences should be kept in mind as you proceed with the migration to ensure a smooth transition and take full advantage of the Stream SDK's capabilities.

## Step-by-Step Migration
The migration from Dolby.io SDK to Stream SDK involves a series of structured steps designed to ensure a seamless transition of your AudioRoom application. This section breaks down the migration process into manageable phases, guiding you through each critical aspect of the transition. Follow these steps closely to adapt your existing SwiftUI application to leverage the capabilities of Stream SDK effectively.

### 5.1 Setup and Initialization
Both SDKs are readily accessible through all major package managers, simplifying their integration into your project. The setup and initialization process for both SDKs involves similar steps, ensuring a smooth transition. You need to make sure that you have updated your `Info.plist` with the required Microphone access key:
- `Privacy - Microphone Usage Description` - "AudioRooms requires microphone access in order to capture and transmit audio

![Screenshot shows permissions in the .plist file](../assets/permissions.png)

### 5.2 User Authentication
User authentication is a critical component of both Dolby.io and Stream SDKs. Although both provide demo tokens (from [Dolby.io dasboard](https://dashboard.dolby.io/dashboard/applications/) or the [AudioRoom tutorial page](https://getstream.io/video/sdk/ios/tutorial/audio-room/#step-3---create--join-a-call)), they require slightly different configurations. Below, we present the configuration steps for each SDK side by side, allowing for an easy comparison and understanding of the differences and similarities.

### Dolby.io SDK Authentication:

Dolby.io SDK utilizes a specific method for user authentication. Follow these steps to configure authentication in your Dolby.io SDK implementation. Here's the code block for setting up user authentication with Dolby.io SDK:

```swift
let token = "THE_YOU_GOT_TOKEN_FROM_DASHBOARD"
VoxeetSDK.shared.initialize(accessToken: token) { closure, isExpired in
   closure(token)
}

let user = VTParticipantInfo(
      externalID: UUID().uuidString,
      name: "Marting",
      avatarURL: "https://getstream.io/static/2796a305dd07651fcceb4721a94f4505/a3911/martin-mitrevski.webp"
)

VoxeetSDK.shared.session.open(info: user) { error in
      if let error {
         /* Do something with the error */
      } else {
         /* Do something with the user */
      }
}
```

While Stream's SDK does that with the following code:
```swift
private var client: StreamVideo
private let apiKey: String = "" // The API key can be found in the Credentials section
private let userId: String = "" // The User Id can be found in the Credentials section
private let token: String = "" // The Token can be found in the Credentials section

let user = User(
   id: userId,
   name: "Martin", // name and imageURL are used in the UI
   imageURL: .init(string: "https://getstream.io/static/2796a305dd07651fcceb4721a94f4505/a3911/martin-mitrevski.webp")
)

 // Initialize Stream Video client
self.client = StreamVideo(
   apiKey: apiKey,
   user: user,
   token: .init(stringLiteral: token)
)
```

### 5.3 Conference/Call Management
Managing conferences in Dolby.io SDK and calls in Stream SDK involves different approaches, particularly in how the primary object that manages the conference or call is handled and interacted with.

#### Dolby.io Conference Management:

In the Dolby.io SDK, the management of a conference is centered around the SDK's singleton, which houses a `ConferenceService`. This service is the key to interacting with the currently active conference. Here's a brief overview:

- **Singleton Pattern**: Dolby.io SDK uses a singleton pattern to manage conferences.
- **Conference Service**: The `ConferenceService` within the singleton is responsible for all conference-related operations.
- **Active Conference Interaction**: The `ConferenceService` allows for interaction with the active conference, handling tasks like joining, leaving, or managing the conference.
- **Not Swift Concurrency**: The API relies on completionHandlers to inform calling points about the result of each call.

```swift
// Create a new conference
VoxeetSDK.shared
   .conference
   .create(options: options) { conference in 
      // Conference was created succesfully
   } fail: { 
      // Conference creation failed
   }

// Join a conference
VoxeetSDK.shared
   .conference
   .join(conference: conference) { response in
         // Succefully joined the conference
   } fail: { 
      // Failed to join the conference
   }
```

Conversely, the Stream SDK adopts a different approach. It creates Call objects from the StreamVideo client, and these call objects are then used throughout the lifecycle of the call for various operations.

1. **Direct Object Creation**: Stream SDK allows for the creation of call objects directly from the StreamVideoClient.
2. **Lifecycle Management**: The Call object in Stream SDK manages all aspects of the call's lifecycle.
3. **Operation Handling**: This object is used for performing operations during the call, including joining, leaving, and managing call features.
4. **Swift Concurrency**: Call's API is built with Swift Concurrency in mind, providing full support on all operations using the conveninent `try await ...`.

```swift
private let callId: String = "" // The CallId can be found in the Credentials section

// Create the call object
self.call = client.call(callType: "audio_room", callId: callId)

// Join the call
// - Allows you to define the members of this audioRoom.
// - Allows you to define custom fields that will be appended on the call object.
try await call.join(
    create: true,
    options: .init(
        members: [
            .init(userId: "john_smith"),
            .init(userId: "jane_doe"),
        ],
        custom: [
            "title": .string("SwiftUI heads"),
            "description": .string("Talking about SwiftUI")
        ]
    )
)
```

### 5.4 Advanced Features
The Stream SDK comes with a built-in permission system, providing a foundational layer for implementing custom user interaction features in your application. This system is particularly useful for managing user roles and permissions dynamically during an audio call.

- **Built-In Functionality**: The permission system is an integral part of the Stream SDK, eliminating the need for external dependencies or complex custom implementations.
- **Flexibility and Control**: It offers granular control over user roles and actions within a call, enabling a more tailored user experience.

#### Implementing "Request to Speak" Feature:

With the Stream SDK's permission system, you can implement a "Request to Speak" feature, where participants can request permission to speak, and the host or moderator can grant or deny this request. This feature enhances the interactivity and orderliness of your AudioRoom, especially in scenarios with multiple participants.

- **User Request Handling**: Participants can send a request to speak, which is managed by the SDK's permission system.
- **Moderator Control**: The host or moderator can easily review and respond to these requests, maintaining a smooth flow of conversation.

Requesting permission to speak is easy. Let's first have a quick look at how the SDK call object exposes this:

```swift
let response = try await call.request(permissions: [.sendAudio])
```

Permission requests are exposed from `call.state` on the `permissionRequests` published variable.
```swift
if let request = call.state.permissionRequests.first {
    // reject it
    request.reject()

    // grant it
    try await call.grant(request: request)
}
```

By integrating these advanced features, your AudioRoom application not only gains enhanced functionality but also provides a more engaging and controlled environment for users. This makes the Stream SDK a powerful tool for developing sophisticated audio conferencing applications.

## Sample Code Comparison

The end result for the app built with Stream SDK is 220 lines (for a fully working AudioRoom app)
```swift
import StreamVideoSwiftUI
import SwiftUI
import StreamVideo

@main
struct AudioRoomsApp: App {
    @State var call: Call
    @ObservedObject var state: CallState
    @State private var callCreated: Bool = false

    private var client: StreamVideo
    private let apiKey: String = "" // The API key can be found in the Credentials section
    private let userId: String = "" // The User Id can be found in the Credentials section
    private let token: String = "" // The Token can be found in the Credentials section
    private let callId: String = "" // The CallId can be found in the Credentials section

    init() {
        let user = User(
            id: userId,
            name: "Martin", // name and imageURL are used in the UI
            imageURL: .init(string: "https://getstream.io/static/2796a305dd07651fcceb4721a94f4505/a3911/martin-mitrevski.webp")
        )

        // Initialize Stream Video client
        self.client = StreamVideo(
            apiKey: apiKey,
            user: user,
            token: .init(stringLiteral: token)
        )

        // Initialize the call object
        let call = client.call(callType: "audio_room", callId: callId)

        self.call = call
        self.state = call.state
    }

    var body: some Scene {
        WindowGroup {
            VStack {
                if callCreated {
                    DescriptionView(
                        title: call.state.custom["title"]?.stringValue,
                        description: call.state.custom["description"]?.stringValue,
                        participants: call.state.participants
                    )
                    ParticipantsView(
                        participants: call.state.participants
                    )
                    Spacer()
                    ControlsView(call: call, state: state)
                } else {
                    Text("loading...")
                }
            }.task {
                Task {
                    guard !callCreated else { return }
                    try await call.join(
                        create: true,
                        options: .init(
                            members: [
                                .init(userId: "john_smith"),
                                .init(userId: "jane_doe"),
                            ],
                            custom: [
                                "title": .string("SwiftUI heads"),
                                "description": .string("talking about SwiftUI")
                            ]
                        )
                    )
                    callCreated = true
                }
            }
        }
    }
}

struct ControlsView: View {
    var call: Call
    @ObservedObject var state: CallState

    var body: some View {
        HStack {
            MicButtonView(microphone: call.microphone)
            LiveButtonView(call: call, state: state)
        }
    }
}

struct DescriptionView: View {
    var title: String?
    var description: String?
    var participants: [CallParticipant]

    var body: some View {
        VStack {
            VStack {
                Text("\(title ?? "")")
                  .font(.title)
                  .frame(maxWidth: .infinity, alignment: .leading)
                  .lineLimit(1)
                  .padding([.bottom], 8)

                Text("\(description ?? "")")
                  .font(.body)
                  .frame(maxWidth: .infinity, alignment: .leading)
                  .lineLimit(1)
                  .padding([.bottom], 4)

                Text("\(participants.count) participants")
                  .font(.caption)
                  .frame(maxWidth: .infinity, alignment: .leading)
            }.padding([.leading, .trailing])
        }
    }
}

struct LiveButtonView: View {
    var call: Call
    @ObservedObject var state: CallState

    var body: some View {
        if state.backstage {
            Button {
                Task {
                    try await call.goLive()
                }
            } label: {
                Text("Go Live")
            }
            .buttonStyle(.borderedProminent).tint(.green)
        } else {
            Button {
                Task {
                    try await call.stopLive()
                }
            } label: {
                Text("Stop live")
            }
            .buttonStyle(.borderedProminent).tint(.red)
        }
    }
}

struct MicButtonView: View {
    @ObservedObject var microphone: MicrophoneManager

    var body: some View {
        Button {
           Task {
               try await microphone.toggle()
           }
        } label: {
            Image(systemName: microphone.status == .enabled ? "mic.circle" : "mic.slash.circle")
                .foregroundColor(microphone.status == .enabled ? .red : .primary)
                .font(.title)
        }
    }
}

struct ParticipantsView: View {
    var participants: [CallParticipant]

    var body: some View {
        LazyVGrid(columns: [GridItem(.adaptive(minimum: 100))], spacing: 20) {
            ForEach(participants) {
                ParticipantView(participant: $0)
            }
        }
    }
}

struct ParticipantView: View {
    var participant: CallParticipant
    
    var body: some View {
        VStack{
            ZStack {
                Circle()
                    .fill(participant.isSpeaking ? .green : .white)
                    .frame(width: 68, height: 68)
                AsyncImage(
                    url: participant.profileImageURL,
                    content: { image in
                        image.resizable()
                            .aspectRatio(contentMode: .fit)
                            .frame(maxWidth: 64, maxHeight: 64)
                            .clipShape(Circle())
                    },
                    placeholder: {
                        Image(systemName: "person.crop.circle").font(.system(size: 60))
                    }
                )
            }
            Text("\(participant.name)")
        }
    }
}

struct PermissionRequestsView: View {
    var call: Call
    @ObservedObject var state: CallState

    var body: some View {
        if let request = state.permissionRequests.first {
            HStack {
                Text("\(request.user.name) requested to \(request.permission)")
                Button {
                   Task {
                       try await call.grant(request: request)
                   }
                } label: {
                    Label("", systemImage: "hand.thumbsup.circle").tint(.green)
                }
                Button(action: request.reject) {
                    Label("", systemImage: "hand.thumbsdown.circle.fill").tint(.red)
                }
            }
        }
    }
}
```
while for the one built with Dolby SDK it's close to 400 lines:
```swift
import SwiftUI
import VoxeetSDK
import Combine

@main
struct DolbyAudioRoomApp: App {
    private static let token: String = """
    eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJpc3MiOiJkb2xieS5pbyIsImlhdCI6MTcwMTk1ODQ0NSwic3ViIjoid18xOEYwcFNvcVp4eFcxb2tFVGJBZz09IiwiYXV0aG9yaXRpZXMiOlsiUk9MRV9DVVNUT01FUiJdLCJ0YXJnZXQiOiJzZXNzaW9uIiwib2lkIjoiNzNkOTdhODgtZjg3Mi00ZTBjLTg2ZjItZDRjY2ZhZDRhODlmIiwiYWlkIjoiZTRmYTg2YjgtOTFmMS00YjQ5LWFkYzUtZjQ4ZTE5M2U2YWQ1IiwiYmlkIjoiOGEzNjllNDU4YzEwMDlmOTAxOGMyNTBlMDNkYTRiMjciLCJleHAiOjE3MDIwNDQ4NDV9.40cAEHUF0E7dUEqqQRFwdPo-a8GhEz_ZrhgGVL2ycbtgEYHC06302J0GQwrJghT1UnuJvdI4bH5vK8lQIIfaKg
    """
    private static let callId: String = "qSYrSp5SnCHX"

    @State private var callCreated = false
    @StateObject private var viewModel: VoxeetSDKViewModel

    init() {
        self._viewModel = .init(wrappedValue: .init(Self.token, callId: Self.callId))
    }

    var body: some Scene {
        WindowGroup {
            VStack {
                DescriptionView(
                    viewModel: viewModel,
                    title: viewModel.callId,
                    description: "Call Description n/a",
                    participants: viewModel.participants
                )
                ParticipantsView(
                    viewModel: viewModel
                )
                Spacer()
                ControlsView(viewModel: viewModel)
            }
        }
    }
}

final class VoxeetSDKViewModel: ObservableObject, VTConferenceDelegate {

    @Published var participants: [VTParticipant] = []
    @Published var isMuted: Bool = false
    @Published var speakingParticipants: [VTParticipant] = []
    @Published var hasActiveCall = false {
        didSet {
            if hasActiveCall {
                speakingParticipantsCancellable = Timer
                    .publish(every: 1, on: .main, in: .default)
                    .autoconnect()
                    .receive(on: DispatchQueue.global(qos: .userInteractive))
                    .sink { [weak self] _ in self?.updateSpeakingParticipants() }
            } else {
                speakingParticipantsCancellable?.cancel()
            }
        }
    }

    var localParticipant: VTParticipant? { VoxeetSDK.shared.session.participant }

    private var speakingParticipantsCancellable: AnyCancellable?
    let callId: String

    init(_ token: String, callId: String) {
        self.callId = callId
        VoxeetSDK.shared.initialize(accessToken: token) { [token] closure, isExpired in
            closure(token)
        }

        VoxeetSDK.shared.notification.push.type = .none
        VoxeetSDK.shared.conference.defaultBuiltInSpeaker = true
        VoxeetSDK.shared.conference.defaultVideo = false

        VoxeetSDK.shared.conference.delegate = self
    }

    @discardableResult
    func connectUser(name: String, avatarURL: String? = nil) async throws -> VTParticipantInfo {
        try await withUnsafeThrowingContinuation { continuation in
            let user = VTParticipantInfo(
                externalID: UUID().uuidString,
                name: name,
                avatarURL: avatarURL
            )

            VoxeetSDK.shared.session.open(info: user) { error in
                if let error {
                    continuation.resume(throwing: error)
                } else {
                    continuation.resume(returning: user)
                }
            }
        }
    }

    @discardableResult
    func joinCall() async throws -> VTConference {
        try await withUnsafeThrowingContinuation { continuation in
            let options = VTConferenceOptions()
            options.params.dolbyVoice = true
            options.alias = callId

            VoxeetSDK.shared
                .conference
                .create(options: options) { conference in
                    debugPrint(conference)
                    VoxeetSDK.shared
                        .conference
                        .join(conference: conference) { response in
                            debugPrint(response)
                            DispatchQueue.main.async { [weak self] in
                                self?.isMuted = VoxeetSDK.shared.conference.isMuted()
                                self?.hasActiveCall = true
                            }
                            continuation.resume(returning: conference)
                        } fail: { continuation.resume(throwing: $0) }

                } fail: { continuation.resume(throwing: $0) }
        }
    }

    func toggleAudio() {
        let newValue = !isMuted
        VoxeetSDK.shared.conference.mute(newValue) { [weak self] error in
            DispatchQueue.main.async {
                if let error {
                    debugPrint("\(error)")
                } else {
                    self?.isMuted = newValue
                }
            }
        }
    }

    func leave() {
        VoxeetSDK.shared.conference.leave { error in
            if let error {
                debugPrint("\(error)")
            } else {
                DispatchQueue.main.async { [weak self] in
                    self?.hasActiveCall = false
                }
            }
        }
    }

    func statusUpdated(status: VTConferenceStatus) {

    }

    func permissionsUpdated(permissions: [Int]) {

    }

    func participantAdded(participant: VTParticipant) {
        updateParticipants()
    }

    func participantUpdated(participant: VTParticipant) {
        updateParticipants()
    }

    func streamAdded(participant: VTParticipant, stream: MediaStream) {
        updateParticipants()
    }

    func streamUpdated(participant: VTParticipant, stream: MediaStream) {
        updateParticipants()
    }

    func streamRemoved(participant: VTParticipant, stream: MediaStream) {
        updateParticipants()
    }

    private func updateParticipants() {
        participants = VoxeetSDK.shared.conference
            .current?
            .participants
            .filter({ $0.streams.isEmpty == false }) ?? []
    }

    private func updateSpeakingParticipants() {
        let localParticipant = self.localParticipant
        let speakingParticipants = participants
            .filter {
                if $0.id != nil, $0.id == localParticipant?.id {
                    if !isMuted {
                        return VoxeetSDK.shared.conference.isSpeaking(participant: $0)
                    } else {
                        return false
                    }
                } else {
                    return VoxeetSDK.shared.conference.isSpeaking(participant: $0)
                }
            }

        DispatchQueue.main.async { [weak self] in
            self?.speakingParticipants = speakingParticipants
        }
    }
}

struct DescriptionView: View {
    @ObservedObject var viewModel: VoxeetSDKViewModel
    var title: String?
    var description: String?
    var participants: [VTParticipant]

    var body: some View {
        VStack {
            VStack {
                Text("\(title ?? "")")
                    .font(.title)
                    .frame(maxWidth: .infinity, alignment: .leading)
                    .lineLimit(1)
                    .padding([.bottom], 8)

                if viewModel.hasActiveCall {
                    Text("\(description ?? "")")
                        .font(.body)
                        .frame(maxWidth: .infinity, alignment: .leading)
                        .lineLimit(1)
                        .padding([.bottom], 4)

                    Text("\(participants.count) participants")
                        .font(.caption)
                        .frame(maxWidth: .infinity, alignment: .leading)
                }
            }.padding([.leading, .trailing])
        }
    }
}

struct ControlsView: View {
    @ObservedObject var viewModel: VoxeetSDKViewModel

    var body: some View {
        HStack {
            MicButtonView(viewModel: viewModel)
            LiveButtonView(viewModel: viewModel)
        }
    }
}

struct MicButtonView: View {

    @ObservedObject var viewModel: VoxeetSDKViewModel

    var body: some View {
        if viewModel.hasActiveCall {
            Button {
                viewModel.toggleAudio()
            } label: {
                Image(systemName: viewModel.isMuted ? "mic.slash.circle" : "mic.circle")
                    .foregroundColor(viewModel.isMuted ? .red : .primary)
                    .font(.title)
            }
        } else {
            EmptyView()
        }
    }
}

struct LiveButtonView: View {

    @ObservedObject var viewModel: VoxeetSDKViewModel

    var body: some View {
        if viewModel.hasActiveCall {
            Button {
                Task {
                    viewModel.leave()
                }
            } label: {
                Text("Leave")
            }
            .buttonStyle(.borderedProminent).tint(.red)
        } else {
            Button {
                Task {
                    do {
                        try await viewModel.connectUser(
                            name: NameGenerator.getRandomName(),
                            avatarURL: "https://picsum.photos/120"
                        )
                        try await viewModel.joinCall()
                    } catch {
                        fatalError("\(error)")
                    }
                }
            } label: {
                Text("Join")
            }
        }
    }
}

struct ParticipantView: View {
    var participant: VTParticipant
    let viewModel: VoxeetSDKViewModel

    @State private var isSpeaking = false

    var body: some View {
        VStack{
            ZStack {
                Circle()
                    .fill(isSpeaking ? .green : .white)
                    .frame(width: 68, height: 68)
                    .overlay(
                        AsyncImage(
                            url: .init(string: participant.info.avatarURL ?? ""),
                            content: { image in
                                image.resizable()
                                    .aspectRatio(contentMode: .fit)
                                    .frame(maxWidth: 64, maxHeight: 64)
                                    .clipShape(Circle())
                            },
                            placeholder: {
                                Image(systemName: "person.crop.circle").font(.system(size: 60))
                            }
                        )
                    )
            }
            if participant == viewModel.localParticipant {
                Text("\(participant.info.name ?? "N/A")(You)")
            } else {
                Text("\(participant.info.name ?? "N/A")")
            }
        }
        .onReceive(viewModel.$speakingParticipants) { speakingParticipants in
            isSpeaking = speakingParticipants.first { $0.id != nil && $0.id == participant.id } != nil
        }
    }
}

struct ParticipantsView: View {
    @ObservedObject var viewModel: VoxeetSDKViewModel

    var body: some View {
        if viewModel.hasActiveCall {
            LazyVGrid(columns: [GridItem(.adaptive(minimum: 100))], spacing: 20) {
                ForEach(viewModel.participants, id: \.info) {
                    ParticipantView(participant: $0, viewModel: viewModel)
                }
            }
        }
    }
}
```

## Support and Resources
For comprehensive guidance on working with the Stream SDK, we recommend exploring the following tutorials provided by Stream. These resources offer in-depth insights into building various types of applications, including AudioRoom, Livestream, and Video Calling, using the Stream SDK.

1. **AudioRoom Tutorial**:
   - **Link**: [Stream AudioRoom Tutorial](https://getstream.io/video/sdk/ios/tutorial/audio-room/)
   - **Overview**: This tutorial focuses on building an AudioRoom application. It covers everything from setup and configuration to implementing key features specific to audio conferencing.
   - **Useful For**: Developers looking to build or migrate audio conferencing applications.

2. **Livestream Tutorial**:
   - **Link**: [Stream Livestream Tutorial](https://getstream.io/video/sdk/ios/tutorial/livestreaming/)
   - **Overview**: This resource guides you through creating a livestreaming application. It includes details on setting up live video streams and managing interactive features.
   - **Useful For**: Those interested in integrating live video streaming functionalities into their applications.

3. **Video Calling Tutorial**:
   - **Link**: [Stream Video Calling Tutorial](https://getstream.io/video/sdk/ios/tutorial/video-calling/)
   - **Overview**: This tutorial provides insights into developing a video calling feature using Stream SDK. It details the implementation of video calls, handling call states, and UI integration.
   - **Useful For**: Developers aiming to add or enhance video calling capabilities in their apps.

Leveraging these tutorials will not only assist you in the migration process but also expand your understanding and skills in building diverse applications with the Stream SDK. Each tutorial is designed to address specific use cases and functionalities, making them valuable resources for developers at any skill level. Additionally, for any specific queries or support, the Stream developer community and their support team are available to assist you.


## Conclusion

As we reach the end of this migration guide, it's clear that the Stream SDK stands out as a more feature-rich and user-friendly option compared to Dolby.io SDK, especially for developers working in the modern iOS ecosystem. Stream's commitment to leveraging the latest technologies in Swift and SwiftUI makes it not only a future-proof choice but also ensures a smoother and more efficient development experience.

The Stream SDK's extensive feature set, including its built-in permission system, advanced call management capabilities, and optimized support for SwiftUI, offers a comprehensive toolkit for building sophisticated Voice and Video applications. These features not only enhance the functionality of your app but also provide a more engaging user experience.

Furthermore, Stream's utilization of modern Swift technologies, like concurrency, makes it a more appealing option for developers looking to harness the full potential of the latest iOS development trends. This modern approach simplifies the coding process, reduces development time, and improves overall app performance.

In summary, by migrating to the Stream SDK, you're not just updating your tech stack; you're taking a significant step forward in delivering a superior audio conferencing experience to your users. Stream SDK empowers you to build more dynamic, scalable, and feature-rich applications with ease and efficiency. Embrace this migration as an opportunity to elevate your AudioRoom app to new heights, leveraging the best of what modern technology has to offer.

We hope this guide has been a valuable resource in your migration journey and look forward to seeing the innovative applications you will create with the Stream SDK.
